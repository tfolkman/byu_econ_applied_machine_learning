{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Python\n",
    "\n",
    "Hopefully now you are feeling a bit more comfortable with Python, Kaggle, and modeling. \n",
    "\n",
    "This next homework will test your classification abilities. We will be trying to predict whether a person survived the Titantic:\n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "The evalution metric for Kaggle is accuracy, but please also explore how well your model does on multiple metrics like F1, precision, recall, and area under the ROC curve.\n",
    "\n",
    "### Grading\n",
    "\n",
    "This homework is due **March 8, 2018 by midnight Utah time.** By that time, you need to have committed all your code to your github and submitted a link to your work to the TA. We can see on your Github account when you last committed code. :)\n",
    "\n",
    "Rubric:\n",
    "\n",
    "* Code Quality - 10%\n",
    "* Storytelling - 10%\n",
    "* Result on Kaggle - 5%\n",
    "* Describing, Cleaning, and Visualizing data - 25%\n",
    "* Modeling - 50%\n",
    "\n",
    "More specifically, for modeling we will look for: \n",
    "\n",
    "* Model Selection: Did you try multiple models? Why did you choose these models? How do they work? What are they assumptions? And how did you test/account for them? How did you select hyper-parameters?\n",
    "* Model evaluation: Did you evaluate your model on multiple metrics? Where does your model do well? Where could it be improved? How are the metrics different?\n",
    "* Model interpretation: What do the model results tell you? Which variables are important? High bias or variance and how did you / could you fix this? How confident are you in your results? \n",
    "* Model usefulness: Do you think your final model was useful? If so, how would you recommend using it? Convince us, that if we were a company, we would feel comfortable using your model with our users. Think about edge cases as well - are there certain areas that the model performs poorly on? Best on? How would you handle these cases, if say Zillow wanted to leverage your model realizing that bad recommendations on sale prices would hurt customer trust and your brand. This section also falls into the storytelling aspect of the grading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
